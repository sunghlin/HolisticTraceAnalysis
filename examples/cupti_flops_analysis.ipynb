{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f114ee",
   "metadata": {},
   "source": [
    "## CUPTI Counter / FLOPs Analysis\n",
    "\n",
    "### About\n",
    "\n",
    "In this demo we leverage the pytorch profiler to capture performance characteristics of CUDA kernels. See the section below on how to collect counters using pytorch profiler.\n",
    "\n",
    "### Motivation and context\n",
    "\n",
    "Performance counters measured on the GPU kernels can provide insights on how to speed up GPU kernels, conduct roofline analysis and other low level optimizations. Profiling tools like NSight Compute provide the ability achieve this interactively but they do not work well on remote application, jobs running on a cluster etc.\n",
    "\n",
    "PyTorch profiler has an alternative lightweight API that gives uses [CUPTI Range Profiler API](https://docs.nvidia.com/cupti/r_main.html#r_profiler) to program and measure detailed performance counters from the device. The underlying mechanism is similar to what NSight uses but this solution is easier to deploy. For example, the application does not have to be launched with NSight compute. Also it supports the same list of [performance metrics](https://docs.nvidia.com/cupti/r_main.html#r_profiler) as NSight. Please see this [PR](https://github.com/pytorch/pytorch/pull/94689) for more details\n",
    "\n",
    "Performance measurements are emitted to the trace either per kernel or for the entire performance profiling region.\n",
    "When the CUPTI Profiler mode is enabled the PyTorch trace will contain the performance measurement values annotated in the GPU kernel events.\n",
    "* The events are emitted under a `cuda_profiler_range` category\n",
    "* The counter values are contained inside the args json part of the trace.\n",
    "\n",
    "The CPU operators continue to be emitted as usual.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Collecting the trace with CUPTI Profiler Counters\n",
    "One can collect performance metrics by adding the list of metrics using the experimental config option in pytorch profiler. Please see this [PR](https://github.com/pytorch/pytorch/pull/94689) for more details\n",
    "```\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CUDA, torch.profiler.ProfilerActivity.CPU],\n",
    "    record_shapes=True,\n",
    "    on_trace_ready=trace_handler,\n",
    "    experimental_config=torch.profiler._ExperimentalConfig(\n",
    "        profiler_metrics=[\n",
    "            \"kineto__tensor_core_insts\",\n",
    "             \"dram__bytes_read.sum\",\n",
    "             \"dram__bytes_write.sum\"],\n",
    "    profiler_measure_per_kernel=True),\n",
    ") as prof:\n",
    "    res = train_batch(modeldef)\n",
    "    prof.step()```\n",
    "```\n",
    "The trace in this example was collected using param benchmarks. Run using\n",
    "```\n",
    "# Inside dir \"param/train/compute\"\n",
    "> python -m python.pytorch.run_benchmark -c python/examples/pytorch/configs/alex_net.json -p -i 1 -d cuda --cupti-profiler --cupti-profiler-measure-per-kernel\n",
    "```\n",
    "\n",
    "#### Trace Analysis\n",
    "\n",
    "To run this demo notebook on your laptop\n",
    "1. Clone the repo `git clone https://github.com/fairinternal/TraceAnalyzer.git`\n",
    "1. [Optional and recommended] Setup a venv or conda environment. See README for details.\n",
    "1. Set the `trace_dir` parameter in the next cell to the location of the folder containing your collected pytorch profiler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e32f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:11:16,106 - hta - trace.py:L374 - INFO - /Users/bcoutinho/Work/hta/HolisticTraceAnalysis/tests/data/cupti_profiler\n",
      "2023-03-31 11:11:16,125 - hta - trace_file.py:L98 - INFO - Rank to trace file map:\n",
      "{0: '/Users/bcoutinho/Work/hta/HolisticTraceAnalysis/tests/data/cupti_profiler/benchmark_result_924719_1679055439_trace.json.gz'}\n",
      "2023-03-31 11:11:16,126 - hta - trace.py:L501 - INFO - ranks=[0]\n",
      "2023-03-31 11:11:16,184 - hta - trace.py:L113 - INFO - Parsed /Users/bcoutinho/Work/hta/HolisticTraceAnalysis/tests/data/cupti_profiler/benchmark_result_924719_1679055439_trace.json.gz time = 0.01 seconds mem = 3.25 MB\n",
      "2023-03-31 11:11:16,273 - hta - trace.py:L623 - WARNING - ProfilerStep not found in the trace. The analysis result may not be accurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bcoutinho/Work/hta/HolisticTraceAnalysis/hta/common/trace.py:296: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[df[\"stream\"].lt(0), \"iteration\"] = df[\"ts\"].apply(_get_profiler_step)\n"
     ]
    }
   ],
   "source": [
    "from hta.trace_analysis import TraceAnalysis\n",
    "from hta.analyzers.counters_analysis import CountersAnalysis, CUDA_SASS_INSTRUCTION_COUNTER_FLOPS\n",
    "trace_prefix = \"~/Work/hta/HolisticTraceAnalysis/\"\n",
    "trace_dir = f\"{trace_prefix}/tests/data/cupti_profiler/\"\n",
    "analyzer = TraceAnalysis(trace_dir=trace_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4603cf0-b044-48d7-ad51-ab0e3aa620f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_kernels = CountersAnalysis.get_counter_data_with_operators(analyzer.t, ranks=[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05225cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>pid</th>\n",
       "      <th>tid</th>\n",
       "      <th>ts</th>\n",
       "      <th>dur</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hfma_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum</th>\n",
       "      <th>...</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_dmul_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hmul_pred_on.sum</th>\n",
       "      <th>index_correlation</th>\n",
       "      <th>iteration</th>\n",
       "      <th>depth</th>\n",
       "      <th>index_runtime</th>\n",
       "      <th>op_stack</th>\n",
       "      <th>top_level_op</th>\n",
       "      <th>bottom_level_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4107</td>\n",
       "      <td>cuda_profiler_range</td>\n",
       "      <td>void at::native::(anonymous namespace)::distri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2498229</td>\n",
       "      <td>121431</td>\n",
       "      <td>0</td>\n",
       "      <td>4866048</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>[cudaLaunchKernel, aten::uniform_, aten::rand]</td>\n",
       "      <td>aten::rand</td>\n",
       "      <td>aten::uniform_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4108</td>\n",
       "      <td>cuda_profiler_range</td>\n",
       "      <td>__missing__</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2619660</td>\n",
       "      <td>121431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3697</td>\n",
       "      <td>[cudaLaunchKernel, cudaFuncSetAttribute, cudaF...</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>aten::convolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4109</td>\n",
       "      <td>cuda_profiler_range</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2741091</td>\n",
       "      <td>121431</td>\n",
       "      <td>0</td>\n",
       "      <td>49561600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3699</td>\n",
       "      <td>[cudaLaunchKernel, aten::add_, cudaFuncSetAttr...</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>aten::add_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4110</td>\n",
       "      <td>cuda_profiler_range</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2862522</td>\n",
       "      <td>121431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>[cudaLaunchKernel, aten::clamp_min_, aten::rel...</td>\n",
       "      <td>aten::relu_</td>\n",
       "      <td>aten::clamp_min_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4111</td>\n",
       "      <td>cuda_profiler_range</td>\n",
       "      <td>void at::native::(anonymous namespace)::max_po...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2983953</td>\n",
       "      <td>121431</td>\n",
       "      <td>0</td>\n",
       "      <td>5971968</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3711</td>\n",
       "      <td>[cudaLaunchKernel, aten::max_pool2d_with_indic...</td>\n",
       "      <td>aten::max_pool2d</td>\n",
       "      <td>aten::max_pool2d_with_indices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  cat  \\\n",
       "0   4107  cuda_profiler_range   \n",
       "1   4108  cuda_profiler_range   \n",
       "2   4109  cuda_profiler_range   \n",
       "3   4110  cuda_profiler_range   \n",
       "4   4111  cuda_profiler_range   \n",
       "\n",
       "                                                name  pid  tid       ts  \\\n",
       "0  void at::native::(anonymous namespace)::distri...    0    0  2498229   \n",
       "1                                        __missing__    0    0  2619660   \n",
       "2  void at::native::elementwise_kernel<128, 2, at...    0    0  2741091   \n",
       "3  void at::native::vectorized_elementwise_kernel...    0    0  2862522   \n",
       "4  void at::native::(anonymous namespace)::max_po...    0    0  2983953   \n",
       "\n",
       "      dur  smsp__sass_thread_inst_executed_op_hadd_pred_on.sum  \\\n",
       "0  121431                                                  0     \n",
       "1  121431                                                  0     \n",
       "2  121431                                                  0     \n",
       "3  121431                                                  0     \n",
       "4  121431                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_hfma_pred_on.sum  \\\n",
       "0                                            4866048     \n",
       "1                                                  0     \n",
       "2                                           49561600     \n",
       "3                                                  0     \n",
       "4                                            5971968     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_dadd_pred_on.sum  ...  \\\n",
       "0                                                  0    ...   \n",
       "1                                                  0    ...   \n",
       "2                                                  0    ...   \n",
       "3                                                  0    ...   \n",
       "4                                                  0    ...   \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_fadd_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_dmul_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_hmul_pred_on.sum  index_correlation  \\\n",
       "0                                                  0                   -1   \n",
       "1                                                  0                   -1   \n",
       "2                                                  0                   -1   \n",
       "3                                                  0                   -1   \n",
       "4                                                  0                   -1   \n",
       "\n",
       "   iteration  depth  index_runtime  \\\n",
       "0         -1      0            473   \n",
       "1         -1      0           3697   \n",
       "2         -1      0           3699   \n",
       "3         -1      0           3701   \n",
       "4         -1      0           3711   \n",
       "\n",
       "                                            op_stack      top_level_op  \\\n",
       "0     [cudaLaunchKernel, aten::uniform_, aten::rand]        aten::rand   \n",
       "1  [cudaLaunchKernel, cudaFuncSetAttribute, cudaF...      aten::conv2d   \n",
       "2  [cudaLaunchKernel, aten::add_, cudaFuncSetAttr...      aten::conv2d   \n",
       "3  [cudaLaunchKernel, aten::clamp_min_, aten::rel...       aten::relu_   \n",
       "4  [cudaLaunchKernel, aten::max_pool2d_with_indic...  aten::max_pool2d   \n",
       "\n",
       "                 bottom_level_op  \n",
       "0                 aten::uniform_  \n",
       "1              aten::convolution  \n",
       "2                     aten::add_  \n",
       "3               aten::clamp_min_  \n",
       "4  aten::max_pool2d_with_indices  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_kernels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5489f0c6-83f0-4a00-9218-f1076b3f6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_kernels[\"flops\"] = 0\n",
    "for counter, flops in CUDA_SASS_INSTRUCTION_COUNTER_FLOPS.items():\n",
    "    gpu_kernels[\"flops\"] += gpu_kernels[counter] * flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b002062f-72cc-474a-8d10-46dddb217915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bottom_level_op</th>\n",
       "      <th>top_level_op</th>\n",
       "      <th>flops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void at::native::(anonymous namespace)::distri...</td>\n",
       "      <td>aten::uniform_</td>\n",
       "      <td>aten::rand</td>\n",
       "      <td>87195648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__missing__</td>\n",
       "      <td>aten::convolution</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>18263449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at...</td>\n",
       "      <td>aten::add_</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>148684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>aten::clamp_min_</td>\n",
       "      <td>aten::relu_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>void at::native::(anonymous namespace)::max_po...</td>\n",
       "      <td>aten::max_pool2d_with_indices</td>\n",
       "      <td>aten::max_pool2d</td>\n",
       "      <td>11943936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ampere_sgemm_32x32_sliced1x4_tn</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>4298637312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>void epilogue::impl::globalKernel&lt;float, float...</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>524288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>aten::clamp_min_</td>\n",
       "      <td>aten::relu_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ampere_sgemm_32x32_sliced1x4_tn</td>\n",
       "      <td>aten::addmm</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>1114112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>void epilogue::impl::globalKernel&lt;float, float...</td>\n",
       "      <td>aten::addmm</td>\n",
       "      <td>aten::linear</td>\n",
       "      <td>131072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "0   void at::native::(anonymous namespace)::distri...   \n",
       "1                                         __missing__   \n",
       "2   void at::native::elementwise_kernel<128, 2, at...   \n",
       "3   void at::native::vectorized_elementwise_kernel...   \n",
       "4   void at::native::(anonymous namespace)::max_po...   \n",
       "..                                                ...   \n",
       "72                    ampere_sgemm_32x32_sliced1x4_tn   \n",
       "73  void epilogue::impl::globalKernel<float, float...   \n",
       "74  void at::native::vectorized_elementwise_kernel...   \n",
       "75                    ampere_sgemm_32x32_sliced1x4_tn   \n",
       "76  void epilogue::impl::globalKernel<float, float...   \n",
       "\n",
       "                  bottom_level_op      top_level_op        flops  \n",
       "0                  aten::uniform_        aten::rand     87195648  \n",
       "1               aten::convolution      aten::conv2d  18263449600  \n",
       "2                      aten::add_      aten::conv2d    148684800  \n",
       "3                aten::clamp_min_       aten::relu_            0  \n",
       "4   aten::max_pool2d_with_indices  aten::max_pool2d     11943936  \n",
       "..                            ...               ...          ...  \n",
       "72                   aten::linear      aten::linear   4298637312  \n",
       "73                   aten::linear      aten::linear       524288  \n",
       "74               aten::clamp_min_       aten::relu_            0  \n",
       "75                    aten::addmm      aten::linear   1114112000  \n",
       "76                    aten::addmm      aten::linear       131072  \n",
       "\n",
       "[77 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_kernels[[\"name\", \"bottom_level_op\", \"top_level_op\", \"flops\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
